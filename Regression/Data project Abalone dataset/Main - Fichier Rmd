---
title: 'Data project: Abalone dataset'
author:
- Breitenstein Thomas
- de Forceville Adrien
- Violeau Alexis
date : 01/11/2020
output: 
  pdf_document : default
  


---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)

abalone <- read_csv("abalone.data", col_names = FALSE)

names(abalone) <- c('Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight','Rings')
abalone$Sex <- as.factor(abalone$Sex)
set.seed(42)

#Splitting dataset in train and test using 70/30 method
indexes <- sample(1:nrow(abalone), size = 0.3 * nrow(abalone))
abalone_train <- abalone[-indexes,]
abalone_test <- abalone[indexes,]
```

Question 1.
Write a mathematical formula modelling the several assumptions in the above description. Describe what
kind of statistical techniques you are going to use to study these hypothesis (confidence intervals, test,. . . )

Lets write $Y$ the age of the abalone and $X$ its height.

We want to test whether there exist a linear relation :  
\begin{equation}
Y = \beta_{0} + \beta_{1}X + \sigma\epsilon
\end{equation}
with $\epsilon$ a standard gaussian noise.

To verify the biologist's asumption, let's perform  a Neyman-pearson statistical test, such that :
\begin{equation}
H_0 : \beta_{1} = 0  \text{ vs }  H_1 : \beta_{1} \neq 0
\end{equation}
Under $H_0$ we know that $T = \frac{\hat{\beta_1}}{\hat\sigma \sqrt{\sum{x_{k}^{2}}}}$ follows a Student law with n-1 degree of freedom

We compute the p-value with R and set a confidence threshold of 99%. Thus, if the p-value < 0.01 we reject $H_0$.




Question 2.
Find summary measures of each variables (mean, variance, range, etc). Examine the variables individually
(univariate). Graphically display each. Describe what you see.

```{r}
summary(abalone)
```


```{r}
boxplot(abalone[,-9][,-1])
```


```{r}
library('gridExtra')
library('ggplot2')
gg1 <- ggplot(abalone, aes(x=Sex)) +
  geom_bar()
gg2 <- ggplot(abalone, aes(x=Length)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
gg3 <-ggplot(abalone, aes(x=Diameter)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
gg4 <- ggplot(abalone, aes(x=Height)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
gg5 <- ggplot(abalone, aes(x=`Whole weight`)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
gg6 <- ggplot(abalone, aes(x=`Shucked weight`)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
gg7 <- ggplot(abalone, aes(x = `Viscera weight`)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
gg8 <- ggplot(abalone, aes(x=`Shell weight`)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 
gg9 <- ggplot(abalone, aes(x=Rings)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666") 


grid.arrange(gg1,gg2,gg3,gg4,gg5,gg6,gg7,gg8,gg9, ncol = 3, nrow = 3)

```
All the 'weight' features seems to have the same shape, with a high positive skewness, and highly concentrated on the low weights (almost uniformly)
Length and Diameter look similars wich is logic for the shape of abalones, and both have negative skewness.
The Rings data can be well approximated by a Normal distribution, but with a longer tail on the right.

Question 3.
Generate a labeled scatterplot of the data. Describe interesting features trends. Does it agree with the
biologists’ hypothesis?


```{r}
library('GGally')
pairplot <- ggpairs(abalone[,-1])
print(pairplot,progress = F)
```

The correlation between the Rings and the Height is high. There seem to exist some relevant linear relation between those two variables. Let's verify it with a linear regression.


Question 4.
Fit a simple linear regression to the data predicting number of rings using height of the abalones.

```{r}
model_height <- lm(Rings~Height, data = abalone)
```

Question 5.
Generate a labeled scatterplot that displays the data and the estimated regression function line. Describe the
line’s fit

```{r}
ggplot(abalone, aes(Height, Rings)) + 
  geom_point() + geom_smooth(method = 'lm')
```

The fit of the linear model is good for low Height, but get worst for high Height. The spread of the error doesn't seem to be constant as the Height gets higher.

Question 6.
Do diagnostics to assess whether the model assumptions are met; if not, appropriately transform height
and/or number of rings and refit your model. Justify your decisions (and recheck your diagnostics).

```{r}
summary(model_height)
```


```{r}
plot(model_height)
```

Point 2052 has a Cook's distance > 1. Point 1418 has a very high residual (> 1). We consider them as outliers and fit our new linear model on the dataset without them.


```{r}
abalone = abalone[-2052,][-1418,]
model_height <- lm(Rings~Height, data = abalone)
```

```{r}
summary(model_height)
```
```{r}
plot(model_height)
```


```{r}
ggplot(abalone[], aes(Height, Rings)) + 
  geom_point() + geom_smooth(method = 'lm')

```
Once again, we realize that the spread of the error gets bigger for high Heights.

We can try to compute a more complex relation between Height and Rings by transforming our data before computing our linear regression.

\begin{equation}
Y \approx \beta_{0} + \beta_{1}X^\alpha
\end{equation}

To compute $\alpha$ we compute the linear regression between log(Height) and log(Rings). 

```{r}
ggplot(abalone[], aes(log(Height), log(Rings))) + 
  geom_point() 
```

We have : 
\begin{equation}
log(Y) \approx \beta_{0} + \beta_{1}log(X)
\end{equation}

and thus we obtain a relation of the kind :

\begin{equation}
Y \approx C \times X^{\alpha}
\end{equation}

We choose to transform $X$ <- $X^\alpha$

```{r}
abalone2 <- abalone

abalone2$Height = abalone$Height^1.4

ggplot(abalone2, aes(Height, Rings)) + 
  geom_point() + geom_smooth(method = 'lm')

model_height2 <- lm(Rings~Height, data = abalone2)

summary(model_height2)
```
Even with data engineering, the model is still irrelevant for high heights. We cannot find easily a good transformation of the data that improve the loss computed by the simplest linear model.

Question 7.
Interpret your final parameter estimates in context. Provide 95% confidence intervals for β0 and β1. Interpret
in context of the problem.

```{r}
confint(model_height, level = 0.95)
```
We have a quite accurate estimation of the parameters of our regression. But intuitively, we tend to predict that the intercept of such a model should be 0 (meaning that a 0-High abalone is 0-Age and has 0-Rings) but we have a confidence interval that does not include 0. It might be a reason to question the accuracy of this model.

Question 8.
Is there a statistically significant relationship between the height and the number of rings (and hence, the
age) of abalones?

The linear model doesn't satisfy the basic hypothesis : the error is not homoscedastic, and the QQ-plot isn't sufficiently close to our aim. Therefore, we cannot decide that there exist a significant linear relationship between the height and the number of rings. Nevertheless, our first linear approximation allow us to get the 'trend' of the relation between the Height and the number of rings without complexity.

